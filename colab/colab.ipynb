{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "155a83d9",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil # Import shutil for file operations\n",
        "\n",
        "# ============== EDIT THESE ==============\n",
        "DRIVE_BASE = \"/content/drive/MyDrive\"\n",
        "DRIVE_PROJECT_FOLDER = \"jersey-number-pipeline\"  # folder under My Drive with your zip and weights\n",
        "DATASET_ZIP = \"jersey-number-pipeline/data/SoccerNet/jersey-2023.zip\" # Add dataset to this location\n",
        "WEIGHTS_FOLDER = \"models\" # Please confirm if this should be 'models' or 'weights'\n",
        "MOUNT_DRIVE = True  # set False if you already mounted in a previous run\n",
        "PERSIST_TO_DRIVE = True  # True = clone repo & SAM to Drive; False = clone to /content (faster, lost when runtime ends)\n",
        "\n",
        "if MOUNT_DRIVE:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "\n",
        "# Determine the base directory for all project components (main repo, sam2, etc.)\n",
        "if PERSIST_TO_DRIVE:\n",
        "    base_project_dir = os.path.join(DRIVE_BASE, DRIVE_PROJECT_FOLDER)\n",
        "    os.makedirs(base_project_dir, exist_ok=True)\n",
        "else:\n",
        "    base_project_dir = \"/content\" # Clone directly into /content for ephemeral\n",
        "    os.makedirs(base_project_dir, exist_ok=True) # Ensure it exists\n",
        "\n",
        "# Main repository (jersey-number-pipeline)\n",
        "repo_root = os.path.join(base_project_dir, \"jersey-number-pipeline\")\n",
        "if not os.path.isdir(os.path.join(repo_root, \".git\")):\n",
        "    get_ipython().system(f'cd \"{base_project_dir}\" && git clone https://github.com/superbolt08/jersey-number-pipeline.git')\n",
        "print(\"Repo root (main project):\", repo_root) # This is the main repo's folder\n",
        "\n",
        "# Change into the base_project_dir for cloning submodules, this is where sam2, reid etc. should reside\n",
        "# This ensures relative paths for subsequent git clones work correctly.\n",
        "get_ipython().run_line_magic(\"cd\", base_project_dir)\n",
        "\n",
        "# SAM (required for legibility) - now cloned relative to base_project_dir\n",
        "if not os.path.isdir(\"sam2\"):\n",
        "    get_ipython().system(\"git clone --recurse-submodules https://github.com/davda54/sam.git sam2\")\n",
        "\n",
        "# Re-ID: centroids-reid (setup.py)\n",
        "os.makedirs(os.path.join(base_project_dir, \"reid\"), exist_ok=True)\n",
        "if not os.path.isdir(os.path.join(base_project_dir, \"reid\", \"centroids-reid\")):\n",
        "    get_ipython().system(f'cd \"{base_project_dir}/reid\" && git clone --recurse-submodules https://github.com/mikwieczorek/centroids-reid.git centroids-reid')\n",
        "    os.makedirs(os.path.join(base_project_dir, \"reid\", \"centroids-reid\", \"models\"), exist_ok=True)\n",
        "\n",
        "# Pose: ViTPose (setup.py)\n",
        "os.makedirs(os.path.join(base_project_dir, \"pose\"), exist_ok=True)\n",
        "if not os.path.isdir(os.path.join(base_project_dir, \"pose\", \"ViTPose\")):\n",
        "    get_ipython().system(f'cd \"{base_project_dir}/pose\" && git clone --recurse-submodules https://github.com/ViTAE-Transformer/ViTPose.git ViTPose')\n",
        "\n",
        "# STR: PARSeq (setup.py)\n",
        "os.makedirs(os.path.join(base_project_dir, \"str\"), exist_ok=True)\n",
        "if not os.path.isdir(os.path.join(base_project_dir, \"str\", \"parseq\")):\n",
        "    get_ipython().system(f'cd \"{base_project_dir}/str\" && git clone --recurse-submodules https://github.com/baudm/parseq.git parseq')\n",
        "\n",
        "print(\"All repositories cloned/checked.\")\n",
        "\n",
        "# repo_root was set above for the main project\n",
        "# drive_project is the parent folder on Drive (e.g., /content/drive/MyDrive/jersey-number-pipeline)\n",
        "drive_project_path = os.path.join(DRIVE_BASE, DRIVE_PROJECT_FOLDER)\n",
        "\n",
        "# Corrected path for DATASET_ZIP\n",
        "drive_zip = os.path.join(drive_project_path, DATASET_ZIP)\n",
        "\n",
        "print(f\"Expected zip file path: {drive_zip}\") # Print expected path for user to verify\n",
        "\n",
        "# FORCIBLY REMOUNT DRIVE to resolve potential caching issues BEFORE os.path.exists\n",
        "# This is done only once at the beginning, so remove the redundant remount here.\n",
        "# print(\"Attempting to forcibly remount Google Drive...\")\n",
        "# drive.mount(\"/content/drive\", force_remount=True)\n",
        "# print(\"Google Drive remounted.\")\n",
        "\n",
        "data_sn_path_local_base = \"/content/data\" # Base path for local extraction\n",
        "data_sn_path_local = os.path.join(data_sn_path_local_base, \"SoccerNet\") # Full local path for SoccerNet data\n",
        "\n",
        "# Path to check if data is already unzipped and reorganized\n",
        "unzipped_data_check_path = os.path.join(data_sn_path_local, \"jersey-2023\")\n",
        "\n",
        "# Check if the data is already unzipped and reorganized\n",
        "if os.path.isdir(unzipped_data_check_path):\n",
        "    print(f\"Dataset already appears to be unzipped and organized at '{unzipped_data_check_path}'. Skipping unzipping and reorganization.\")\n",
        "elif not os.path.exists(drive_zip):\n",
        "    print(f\"ERROR: The dataset zip file '{DATASET_ZIP}' was not found at '{drive_zip}'.\")\n",
        "    print(f\"Please ensure you have uploaded '{DATASET_ZIP}' to your Google Drive folder: '{drive_project_path}'.\")\n",
        "    raise FileNotFoundError(f\"Dataset zip file missing: {drive_zip}\")\n",
        "else:\n",
        "    print(f\"Found dataset zip file at '{drive_zip}'. Proceeding to unzip to local /content.\")\n",
        "\n",
        "    # Ensure clean slate for local extraction\n",
        "    if os.path.exists(data_sn_path_local):\n",
        "        get_ipython().system(f'rm -rf \"{data_sn_path_local}\"/*')\n",
        "    os.makedirs(data_sn_path_local, exist_ok=True)\n",
        "\n",
        "    # Copy the zip file to local /content/tmp for reliable unzipping using shutil.copy\n",
        "    temp_unzip_dir = \"/content/tmp\"\n",
        "    os.makedirs(temp_unzip_dir, exist_ok=True)\n",
        "    temp_zip_path = os.path.join(temp_unzip_dir, os.path.basename(drive_zip))\n",
        "\n",
        "    print(f\"Copying '{drive_zip}' to temporary location '{temp_zip_path}' using shutil.copy...\")\n",
        "    shutil.copy(drive_zip, temp_zip_path)\n",
        "\n",
        "    print(f\"Unzipping '{temp_zip_path}' to '{data_sn_path_local}'...\")\n",
        "    get_ipython().system(f'unzip -o \"{temp_zip_path}\" -d \"{data_sn_path_local}\"') # Removed -q for verbose output\n",
        "\n",
        "    # Clean up the temporary copy\n",
        "    print(f\"Cleaning up temporary zip file: '{temp_zip_path}'\")\n",
        "    get_ipython().system(f'rm \"{temp_zip_path}\"')\n",
        "\n",
        "    print(f\"Dataset extracted to local: {data_sn_path_local}\")\n",
        "\n",
        "    # Create symbolic link from repo's expected data path to local extracted data\n",
        "    # First remove any existing 'data/SoccerNet' dir in repo_root (if it was created in Drive)\n",
        "    repo_data_sn_path = os.path.join(repo_root, \"data\", \"SoccerNet\")\n",
        "    if os.path.exists(repo_data_sn_path):\n",
        "        if os.path.islink(repo_data_sn_path):\n",
        "            get_ipython().system(f'rm \"{repo_data_sn_path}\"')\n",
        "        else:\n",
        "            get_ipython().system(f'rm -rf \"{repo_data_sn_path}\"')\n",
        "    get_ipython().system(f'mkdir -p \"{os.path.dirname(repo_data_sn_path)}\"') # Ensure parent dir exists\n",
        "    get_ipython().system(f'ln -s \"{data_sn_path_local}\" \"{repo_data_sn_path}\"')\n",
        "    print(f\"Symlinked '{data_sn_path_local}' to '{repo_data_sn_path}'\")\n",
        "    get_ipython().system(f'ls -l \"{os.path.dirname(repo_data_sn_path)}\"') # Verify symlink\n",
        "\n",
        "    # The reorganization logic needs to be aware of the new local path structure.\n",
        "    # Check if 'train' and 'test' folders exist directly under local_soccernet_path AND 'jersey-2023' does NOT.\n",
        "    if os.path.isdir(f\"{data_sn_path_local}/train\") and os.path.isdir(f\"{data_sn_path_local}/test\") and not os.path.isdir(f\"{data_sn_path_local}/jersey-2023\"):\n",
        "        print(\"Reorganizing dataset structure: Moving 'train' and 'test' into 'jersey-2023' in local /content.\")\n",
        "        get_ipython().system(f'mkdir -p \"{data_sn_path_local}/jersey-2023\"')\n",
        "        get_ipython().system(f'mv \"{data_sn_path_local}/train\" \"{data_sn_path_local}/jersey-2023/\"')\n",
        "        get_ipython().system(f'mv \"{data_sn_path_local}/test\" \"{data_sn_path_local}/jersey-2023/\"')\n",
        "        print(f\"Contents of {data_sn_path_local} after reorganization:\")\n",
        "        get_ipython().system(f'ls -R \"{data_sn_path_local}\"/')\n",
        "    elif os.path.isdir(f\"{data_sn_path_local}/jersey-2023\"):\n",
        "        print(f\"Dataset extracted directly to {data_sn_path_local}/jersey-2023/.\")\n",
        "    else:\n",
        "        print(\"WARNING: Unexpected dataset structure after unzipping. Please verify local '{data_sn_path_local}' contents.\")\n",
        "\n",
        "drive_weights = os.path.join(drive_project_path, WEIGHTS_FOLDER)\n",
        "\n",
        "# Ensure target directories exist before copying weights\n",
        "get_ipython().system(f'mkdir -p \"{repo_root}/models\" \"{os.path.join(base_project_dir, \"reid\", \"centroids-reid\", \"models\")}\" \"{os.path.join(base_project_dir, \"pose\", \"ViTPose\", \"checkpoints\")}\"')\n",
        "# Suppress output of 'cp' unless there's a problem\n",
        "get_ipython().system(f'cp \"{drive_weights}/models/\"* \"{repo_root}/models/\" 2>/dev/null || true')\n",
        "get_ipython().system(f'cp \"{drive_weights}/reid/\"* \"{os.path.join(base_project_dir, \"reid\", \"centroids-reid\", \"models\")}/\" 2>/dev/null || true')\n",
        "get_ipython().system(f'cp \"{drive_weights}/pose/\"* \"{os.path.join(base_project_dir, \"pose\", \"ViTPose\", \"checkpoints\")}/\" 2>/dev/null || true')\n",
        "print(\"Weights copied.\")\n",
        "\n",
        "get_ipython().system('pip install -q torch torchvision opencv-python Pillow numpy pandas scipy tqdm pytorch-lightning yacs')\n",
        "\n",
        "# Change directory to repo_root for the subprocess call\n",
        "get_ipython().run_line_magic(\"cd\", repo_root)\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Construct the command and environment for the subprocess\n",
        "command = [sys.executable, \"main.py\", \"SoccerNet\", \"test\"]\n",
        "env = os.environ.copy()\n",
        "# PYTHONPATH: sam2 for SAM; reid/centroids-reid so centroid_reid.py can \"from config import cfg\"\n",
        "centroids_reid_root = os.path.join(base_project_dir, \"reid\", \"centroids-reid\")\n",
        "env[\"PYTHONPATH\"] = f\"{os.path.join(base_project_dir, 'sam2')}:{centroids_reid_root}:{env.get('PYTHONPATH', '')}\"\n",
        "\n",
        "print(f\"Attempting to run: {' '.join(command)}\")\n",
        "print(f\"With PYTHONPATH: {env['PYTHONPATH']}\")\n",
        "\n",
        "# Execute main.py using subprocess.run\n",
        "# capture_output=True captures stdout and stderr\n",
        "# text=True decodes stdout/stderr as text\n",
        "result = subprocess.run(command, env=env, capture_output=True, text=True, cwd=repo_root)\n",
        "\n",
        "# Print subprocess output\n",
        "print(\"Standard Output from main.py:\\n\", result.stdout)\n",
        "print(\"Standard Error from main.py:\\n\", result.stderr)\n",
        "\n",
        "if result.returncode != 0:\n",
        "    print(f\"Error executing main.py. Exit code: {result.returncode}\")\n",
        "    print(\"Traceback (if available from main.py subprocess):\\n\", result.stderr)\n",
        "else:\n",
        "    print(\"main.py executed successfully.\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
